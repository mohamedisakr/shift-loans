{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc4f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b018e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan dataset\n",
    "X_train = pd.read_csv(\"raw_data\\X_train.csv\")\n",
    "X_test = pd.read_csv(\"raw_data\\X_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4522f1",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af5277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) What is the percentage of default (\"bad\") loans for the Connecticut ZIP codes in \n",
    "# the test sample (X_train.csv)*?\n",
    "# 0\n",
    "# 17.5\n",
    "# 0.17\n",
    "# 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0222da76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addr_state</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CT</td>\n",
       "      <td>064xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CT</td>\n",
       "      <td>060xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>CT</td>\n",
       "      <td>064xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>CT</td>\n",
       "      <td>067xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>CT</td>\n",
       "      <td>060xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199284</th>\n",
       "      <td>CT</td>\n",
       "      <td>064xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199364</th>\n",
       "      <td>CT</td>\n",
       "      <td>063xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199390</th>\n",
       "      <td>CT</td>\n",
       "      <td>060xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199451</th>\n",
       "      <td>CT</td>\n",
       "      <td>060xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199818</th>\n",
       "      <td>CT</td>\n",
       "      <td>060xx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        addr_state zip_code\n",
       "98              CT    064xx\n",
       "193             CT    060xx\n",
       "218             CT    064xx\n",
       "277             CT    067xx\n",
       "324             CT    060xx\n",
       "...            ...      ...\n",
       "1199284         CT    064xx\n",
       "1199364         CT    063xx\n",
       "1199390         CT    060xx\n",
       "1199451         CT    060xx\n",
       "1199818         CT    060xx\n",
       "\n",
       "[18171 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# condition state = connecticut & bad\n",
    "condition = (X_train['addr_state'] == 'CT') & (X_train['zip_code'])\n",
    "connecticut = X_train.loc[condition]\n",
    "connecticut = connecticut.loc[:, ['addr_state', 'zip_code']]\n",
    "connecticut\n",
    "\n",
    "# percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0e454",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d935587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Choose the correct statements:* --> MCQ\n",
    "# [.] 1. In the test sample, there are 3 times more loans issued for 3 years than for 5 years\n",
    "# 2. Median interest rate in train (X_train.csv) 16.29%\n",
    "# 3. The last loan was issued in August 2020\n",
    "# 4. Default for the top 10% is higher than the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7aa5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the month from issue_d\n",
    "X_train['issue_month'] = X_train['issue_d'].apply(lambda x: int(datetime.strptime(x.split('-')[0],'%b').month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68a7de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the year from issue_d\n",
    "X_train['issue_year'] = X_train['issue_d'].apply(lambda x: int(datetime.strptime(x.split('-')[1],'%Y').year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e61fb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' 36 months', ' 60 months'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term \n",
    "X_train.term.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b8315a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 36 months    903699\n",
       " 60 months    296162\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loans issued for 3 years (36 months) and for 5 years (60 months)\n",
    "loan_term = X_train['term'].value_counts()\n",
    "# type(loan_term)\n",
    "loan_term\n",
    "# loan_term[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff93e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0513671571639844\n"
     ]
    }
   ],
   "source": [
    "# 1. In the test sample, there are 3 times more loans issued for 3 years than for 5 years\n",
    "print(903699/296162)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f01ef2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' 12.99%', ' 10.42%', '  8.99%', ' 11.53%', ' 26.30%', ' 12.12%',\n",
       "       ' 14.65%', ' 13.59%', '  8.18%', ' 13.49%', ' 24.50%', ' 15.31%',\n",
       "       ' 18.99%', ' 17.57%', ' 13.11%', '  6.24%', ' 13.33%', ' 11.99%',\n",
       "       ' 13.67%', '  5.32%', '  6.03%', ' 14.49%', ' 14.99%', ' 13.56%',\n",
       "       '  8.24%', ' 24.99%', '  9.49%', '  6.89%', ' 14.31%', ' 12.39%',\n",
       "       '  9.16%', '  7.89%', ' 13.68%', '  9.17%', ' 12.49%', ' 10.64%',\n",
       "       ' 11.49%', ' 14.09%', ' 12.85%', ' 13.98%', '  8.90%', ' 13.53%',\n",
       "       ' 14.47%', ' 16.99%', '  8.46%', '  6.46%', ' 12.69%', ' 11.39%',\n",
       "       ' 12.79%', ' 15.80%', ' 21.45%', ' 11.44%', ' 10.99%', ' 12.62%',\n",
       "       ' 20.99%', ' 18.25%', '  8.67%', ' 15.41%', ' 11.47%', '  7.99%',\n",
       "       ' 23.05%', ' 10.49%', '  8.59%', ' 14.08%', ' 15.05%', ' 10.16%',\n",
       "       ' 22.45%', '  9.99%', ' 10.41%', ' 10.47%', ' 12.73%', '  7.26%',\n",
       "       ' 16.02%', ' 15.59%', ' 11.71%', ' 12.35%', ' 13.99%', ' 22.99%',\n",
       "       ' 22.39%', '  9.43%', ' 15.61%', ' 12.98%', '  6.62%', '  7.59%',\n",
       "       ' 13.06%', ' 17.19%', '  8.39%', '  9.93%', ' 19.89%', '  6.67%',\n",
       "       ' 11.14%', ' 23.63%', '  7.49%', '  8.19%', '  7.97%', ' 14.33%',\n",
       "       '  7.90%', ' 16.55%', ' 20.00%', ' 19.52%', ' 21.00%', ' 11.67%',\n",
       "       ' 10.78%', ' 16.49%', ' 19.92%', '  6.68%', ' 15.02%', ' 14.16%',\n",
       "       ' 12.29%', ' 10.15%', ' 17.74%', ' 23.28%', '  9.92%', '  7.35%',\n",
       "       '  6.92%', ' 26.24%', ' 20.20%', '  6.19%', ' 13.23%', '  9.75%',\n",
       "       ' 16.14%', ' 11.80%', ' 18.49%', ' 18.45%', ' 23.43%', ' 12.40%',\n",
       "       ' 16.46%', ' 13.18%', ' 17.99%', ' 15.99%', ' 13.65%', ' 11.02%',\n",
       "       ' 12.59%', '  7.69%', '  6.11%', ' 19.99%', ' 11.55%', ' 27.27%',\n",
       "       ' 19.03%', ' 28.18%', '  7.46%', ' 19.19%', ' 25.99%', ' 19.47%',\n",
       "       ' 15.49%', ' 15.22%', ' 19.05%', '  9.44%', ' 18.06%', ' 13.61%',\n",
       "       ' 19.22%', ' 10.75%', '  7.91%', '  9.67%', ' 15.24%', '  7.07%',\n",
       "       ' 11.48%', ' 14.30%', '  7.39%', '  6.97%', ' 30.79%', '  9.80%',\n",
       "       ' 27.79%', ' 16.32%', ' 10.33%', '  9.76%', ' 17.86%', ' 24.08%',\n",
       "       '  7.12%', '  7.24%', ' 19.72%', ' 16.20%', ' 18.54%', ' 22.15%',\n",
       "       ' 17.47%', ' 15.77%', '  8.81%', ' 16.78%', ' 11.06%', ' 16.29%',\n",
       "       ' 21.85%', ' 11.31%', '  7.51%', ' 12.13%', ' 13.35%', ' 19.24%',\n",
       "       '  7.21%', ' 21.48%', ' 18.75%', '  7.02%', ' 10.72%', ' 12.74%',\n",
       "       '  6.99%', ' 24.11%', ' 10.19%', ' 17.27%', '  9.58%', ' 14.46%',\n",
       "       ' 30.99%', ' 17.77%', ' 27.88%', ' 12.05%', '  6.72%', '  6.49%',\n",
       "       ' 26.31%', ' 24.70%', ' 18.84%', ' 20.39%', ' 10.91%', ' 15.04%',\n",
       "       ' 25.83%', '  7.56%', ' 17.49%', ' 29.99%', ' 15.10%', ' 13.44%',\n",
       "       ' 28.14%', ' 18.24%', ' 29.69%', ' 17.97%', ' 14.85%', ' 14.64%',\n",
       "       ' 21.49%', ' 17.09%', ' 26.77%', '  8.38%', '  7.66%', ' 23.99%',\n",
       "       '  8.08%', ' 21.99%', ' 13.58%', ' 25.00%', '  5.31%', ' 14.74%',\n",
       "       ' 25.44%', ' 14.03%', ' 16.12%', ' 19.42%', ' 10.08%', ' 20.50%',\n",
       "       ' 11.12%', ' 21.18%', ' 25.82%', ' 12.42%', '  8.49%', ' 19.20%',\n",
       "       ' 14.52%', ' 18.85%', ' 20.75%', ' 18.55%', ' 11.22%', ' 24.85%',\n",
       "       ' 13.80%', ' 23.13%', ' 28.99%', ' 22.74%', ' 21.15%', '  6.39%',\n",
       "       ' 10.74%', ' 13.85%', '  6.07%', '  7.62%', ' 20.49%', ' 13.05%',\n",
       "       ' 13.08%', ' 19.48%', '  7.84%', '  5.79%', ' 17.56%', ' 20.31%',\n",
       "       ' 21.60%', ' 14.07%', ' 18.94%', ' 16.91%', ' 25.49%', ' 22.20%',\n",
       "       ' 16.40%', ' 18.92%', ' 21.28%', ' 17.14%', ' 17.76%', ' 21.97%',\n",
       "       ' 15.88%', ' 23.88%', ' 30.17%', '  6.08%', '  6.71%', ' 25.57%',\n",
       "       ' 11.05%', ' 14.98%', ' 25.80%', '  5.93%', ' 20.89%', ' 10.90%',\n",
       "       ' 21.36%', ' 12.88%', ' 13.87%', ' 12.61%', '  7.34%', ' 21.98%',\n",
       "       ' 17.10%', ' 10.59%', ' 21.70%', ' 10.65%', ' 24.49%', ' 25.69%',\n",
       "       '  9.32%', ' 16.24%', ' 25.81%', '  7.96%', '  9.71%', ' 14.48%',\n",
       "       ' 26.49%', ' 30.84%', ' 23.40%', ' 10.56%', ' 15.57%', ' 16.59%',\n",
       "       ' 20.55%', ' 25.88%', ' 13.66%', ' 26.06%', ' 20.80%', ' 19.53%',\n",
       "       '  8.94%', '  7.88%', ' 22.91%', ' 12.21%', ' 24.89%', ' 22.47%',\n",
       "       ' 12.68%', '  9.25%', ' 21.74%', '  9.62%', ' 28.72%', ' 14.79%',\n",
       "       ' 28.69%', ' 11.98%', ' 12.22%', ' 14.42%', ' 18.20%', ' 13.57%',\n",
       "       '  6.00%', ' 13.90%', ' 16.00%', ' 23.50%', ' 28.80%', ' 10.07%',\n",
       "       ' 16.77%', ' 24.74%', '  9.63%', '  8.00%', ' 24.37%', ' 14.38%',\n",
       "       ' 30.49%', ' 15.65%', ' 25.28%', ' 11.26%', ' 30.65%', ' 25.29%',\n",
       "       ' 23.32%', ' 11.89%', ' 22.40%', ' 24.24%', ' 16.01%', ' 22.50%',\n",
       "       ' 14.35%', ' 27.49%', ' 21.67%', ' 16.69%', '  6.54%', ' 22.35%',\n",
       "       ' 10.36%', '  7.14%', '  5.99%', ' 22.90%', ' 24.84%', ' 30.94%',\n",
       "       ' 23.83%', ' 14.62%', '  6.17%', ' 23.87%', '  8.60%', ' 25.34%',\n",
       "       '  9.91%', ' 12.53%', ' 25.65%', '  7.29%', ' 10.25%', ' 11.36%',\n",
       "       ' 11.86%', ' 10.00%', ' 26.14%', ' 13.72%', ' 26.99%', ' 12.18%',\n",
       "       ' 12.23%', ' 27.31%', '  5.42%', ' 15.81%', ' 28.34%', ' 22.11%',\n",
       "       ' 22.70%', '  7.40%', ' 15.33%', '  6.83%', ' 18.62%', ' 30.74%',\n",
       "       ' 17.43%', ' 13.92%', ' 30.89%', ' 19.97%', ' 29.49%', ' 15.27%',\n",
       "       ' 16.95%', '  6.91%', ' 22.95%', ' 25.89%', ' 15.68%', ' 14.96%',\n",
       "       ' 23.10%', ' 13.43%', ' 19.36%', ' 15.21%', ' 18.79%', ' 28.92%',\n",
       "       ' 30.75%', ' 11.11%', ' 23.70%', ' 26.57%', ' 12.84%', ' 13.16%',\n",
       "       '  7.74%', ' 18.30%', ' 28.67%', ' 14.27%', ' 18.64%', ' 29.35%',\n",
       "       ' 19.12%', ' 15.58%', ' 13.79%', ' 16.35%', ' 14.26%', ' 14.17%',\n",
       "       ' 16.45%', '  8.88%', ' 14.91%', ' 15.40%', ' 23.76%', ' 10.81%',\n",
       "       '  7.68%', ' 14.83%', ' 25.78%', ' 10.37%', ' 25.09%', ' 17.93%',\n",
       "       ' 18.39%', ' 13.55%', ' 19.69%', ' 14.72%', ' 12.09%', ' 14.11%',\n",
       "       ' 10.38%', ' 17.51%', '  7.43%', ' 11.97%', ' 27.34%', ' 15.20%',\n",
       "       ' 28.88%', ' 24.83%', ' 14.22%', ' 22.78%', ' 25.11%', ' 12.17%',\n",
       "       ' 14.61%', ' 18.17%', ' 16.70%', ' 17.58%', ' 17.88%', ' 15.95%',\n",
       "       ' 11.28%', ' 17.15%', ' 16.63%', '  9.20%', ' 10.62%', ' 14.59%',\n",
       "       ' 19.91%', ' 15.96%', ' 15.70%', ' 13.48%', '  9.56%', ' 23.33%',\n",
       "       ' 15.23%', '  7.75%', ' 11.83%', ' 22.06%', '  8.32%', '  7.37%',\n",
       "       ' 16.89%', ' 29.67%', ' 28.49%', ' 10.95%', '  9.64%', ' 24.20%',\n",
       "       ' 15.62%', ' 13.22%', ' 17.80%', ' 29.96%', ' 20.30%', ' 11.03%',\n",
       "       ' 12.87%', ' 17.39%', ' 14.54%', ' 19.13%', '  9.96%', '  9.38%',\n",
       "       ' 20.62%', ' 13.24%', ' 17.46%', ' 22.85%', '  8.70%', ' 11.78%',\n",
       "       ' 17.06%', ' 23.52%', ' 13.47%', '  6.76%', ' 15.28%', '  9.88%',\n",
       "       ' 29.00%', ' 10.83%', ' 11.54%', ' 21.22%', ' 17.30%', '  9.45%',\n",
       "       '  9.02%', ' 19.95%', ' 19.41%', ' 14.50%', ' 15.37%', '  9.51%',\n",
       "       ' 12.80%', ' 11.46%', ' 11.66%', ' 19.29%', ' 27.99%', ' 18.43%',\n",
       "       ' 28.95%', ' 10.96%', ' 11.58%', ' 14.71%', ' 20.25%', ' 15.83%',\n",
       "       ' 20.16%', ' 17.04%', ' 16.82%', ' 16.07%', ' 20.85%', ' 12.04%',\n",
       "       ' 21.14%', ' 24.33%', ' 10.39%', ' 18.21%', ' 14.84%', ' 20.69%',\n",
       "       '  7.05%', ' 28.97%', ' 11.34%', ' 20.40%', ' 17.26%', ' 16.08%',\n",
       "       ' 10.28%', ' 22.94%', ' 12.41%', ' 22.48%', '  9.01%', ' 23.26%',\n",
       "       ' 11.41%', '  9.07%', ' 14.02%', ' 10.20%', ' 20.11%', ' 20.74%',\n",
       "       ' 12.36%', ' 20.48%', ' 17.03%', ' 13.30%', ' 12.92%', ' 12.67%',\n",
       "       ' 11.72%', ' 14.75%', '  8.07%', ' 21.27%', ' 10.14%', ' 10.71%',\n",
       "       ' 11.09%', ' 10.01%', '  8.63%', ' 20.03%', ' 19.04%', ' 19.16%',\n",
       "       ' 19.79%', ' 20.90%', ' 11.63%', ' 23.91%', ' 10.51%', ' 15.45%',\n",
       "       ' 14.18%', ' 10.46%', ' 18.09%', ' 19.74%', ' 24.76%', ' 13.84%',\n",
       "       '  9.33%', ' 12.86%', ' 20.53%', ' 17.34%', ' 14.93%', ' 18.67%',\n",
       "       ' 20.86%', '  9.70%', ' 12.72%', ' 23.22%', ' 28.90%', ' 24.52%',\n",
       "       ' 12.54%', ' 11.91%', ' 13.12%', ' 15.76%', ' 13.04%', ' 22.64%',\n",
       "       ' 16.11%', ' 23.59%', ' 18.07%', ' 14.67%', ' 13.93%', ' 18.91%',\n",
       "       '  9.83%', ' 14.77%', ' 15.25%', ' 11.59%', ' 21.21%', ' 17.50%',\n",
       "       ' 17.44%', ' 19.66%', ' 21.59%', ' 15.29%', ' 13.17%', ' 14.82%',\n",
       "       ' 19.39%', ' 20.77%', ' 15.13%', ' 13.36%', ' 20.17%', ' 21.64%',\n",
       "       ' 18.72%', ' 11.16%', ' 21.82%', ' 18.53%', '  7.42%', ' 13.62%',\n",
       "       ' 18.78%', ' 14.12%', ' 17.54%', ' 19.82%', ' 14.88%', ' 15.01%',\n",
       "       ' 16.33%', ' 15.38%', ' 13.75%'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term mapping\n",
    "X_train.int_rate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "366605c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.99    28586\n",
       "11.99    27545\n",
       "5.32     27417\n",
       "13.99    25416\n",
       "11.49    19940\n",
       "         ...  \n",
       "15.13        1\n",
       "17.50        1\n",
       "19.16        1\n",
       "17.44        1\n",
       "13.75        1\n",
       "Name: int_rate, Length: 669, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert first to float\n",
    "X_train['int_rate'] = X_train['int_rate'].str.replace(\" \", \"\").str.replace(\"%\", \"\").astype('float')\n",
    "X_train['int_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458b7ddf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: ' 12.99%'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:752\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 752\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;66;03m# e.g. \"could not convert string to float: 'a'\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' 12.99%'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 2. Median interest rate in train (X_train.csv) 16.29%\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:11187\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.median\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11169\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11170\u001b[0m     _num_doc,\n\u001b[0;32m  11171\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the median of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11185\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11186\u001b[0m ):\n\u001b[1;32m> 11187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmedian(\u001b[38;5;28mself\u001b[39m, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:10699\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  10692\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10693\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10697\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  10698\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 10699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  10700\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmedian, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  10701\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:10639\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10629\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  10630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  10631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10634\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  10635\u001b[0m     )\n\u001b[0;32m  10636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[0;32m  10637\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  10638\u001b[0m     )\n\u001b[1;32m> 10639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  10641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4471\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   4468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4469\u001b[0m     )\n\u001b[0;32m   4470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py:755\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    752\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;66;03m# e.g. \"could not convert string to float: 'a'\"\u001b[39;00m\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    757\u001b[0m     values[mask] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "\u001b[1;31mTypeError\u001b[0m: could not convert string to float: ' 12.99%'"
     ]
    }
   ],
   "source": [
    "# 2. Median interest rate in train (X_train.csv) 16.29%\n",
    "# X_train['int_rate'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224680aa",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f357dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) For defaulted loans in train versus non-defaulted, tick the correct answers \n",
    "# (use t-test if necessary):*\n",
    "# 1. The share of problem accounts (i.e. acc_now_delinq>0) is approximately the same (for defaulted and non-defaulted loans)\n",
    "# 2. The lower threshold from the credit bureau (fico_range_low) is not significantly different for bad and good\n",
    "# 3. Bad and good do not differ in the difference between the average amount requested and approved\n",
    "# 4. Shares of missing values ​​in mths_since_recent_bc_dlq for bad and good differ significantly\n",
    "# There is no such number here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10e9d1",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70f999f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Check the correct statements:*\n",
    "# 1. It is necessary to carry out income verification (see verification_status values). \n",
    "#     it affects the probability of default\n",
    "# 2. Those who have had their income verified have more income\n",
    "# 3. Those who have had their income verified have less default\n",
    "# 4. Income verification and (loan_amnt - funded_amnt) have a significant (>0.5) \n",
    "#     positive correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f6aeb",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) By how much will the default rate decrease if it is issued only to those who \n",
    "# have at least one mortgage (mort_acc > 0) and an acceptable debt-to-income ratio \n",
    "# (dti < 0.3). What are the correct answers?*\n",
    "# 0.049\n",
    "# 0.5%\n",
    "# 5%\n",
    "# 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9c507",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef395b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) For further questions, you need to split the training sample into two, so that \n",
    "# you learn on one and check the quality on the other. Use X_train2, X_test2, y_train2, \n",
    "# y_test2 = train_test_split(X_train, y_train, test_size=0.33, random_state=100).\n",
    "\n",
    "# Using sklearn and one hot encoding transformation of categorical features where the \n",
    "# number of categories is less than 15, build a decision tree with default parameters \n",
    "# (if necessary, fill in the gaps with -999) on X_train2.\n",
    "\n",
    "# Correct statements:\n",
    "# *\n",
    "# 1. The first feature in the tree changes when you set max_depth=2\n",
    "# 2. Second feature = funded_amnt in the tree with max_depth=2\n",
    "# 3. Tree with unlimited max_depth and random_state=0 gives quality on y_test2 0.28 Gini\n",
    "# 4. Tree with limited max_depth = 10 and random_state=0 gives quality on y_train2 0.285 Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6637c8e",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) Plot a random forest from sklearn on the features prepared for the tree (X_train2). \n",
    "# Use Gini (and y_test2) as a measure of quality. \n",
    "\n",
    "# Choose the correct answers:*\n",
    "# 1. Tree with default max_depth and random_state=0 gives better quality than forest with \n",
    "#     random_state=10 by 0.002\n",
    "# 2. A forest of three trees is better than a forest at default values\n",
    "# 3. Forest at max_depth=10 and other default values ​​does not predict anything\n",
    "# 4. Forest at max_depth=10 and min_samples_leaf=100 works best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74792132",
   "metadata": {},
   "source": [
    "#### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) What feature should be made from emp_length and another categorical feature \n",
    "# with 15 or fewer categories to have the highest default rate?\n",
    "# Consider that we make a decision on at least 100 observations.*\n",
    "# if emp_length=='8 years' & home_ownership=='RENT'\n",
    "# if emp_length=='4 years' & purpose=='small_business'\n",
    "# if emp_length=='1 year' & term=='60 months'\n",
    "# if emp_length=='3 years' & verification_status=='Verified'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade576d",
   "metadata": {},
   "source": [
    "#### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3081495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) In further questions, we will use the original X_train, y_train. Let's divide them into \n",
    "# training and test sets: X_train2, X_test2, y_train2, y_test2 = \n",
    "#     train_test_split(X_train, y_train, test_size=0.33, random_state=100). \n",
    "\n",
    "# Choose the correct answers:*\n",
    "# 1. catboost with iterations=80 and other default parameters, \n",
    "#     works worse than a forest, but better than trees, if we compare models from previous questions\n",
    "# 2. catboost with iterations=80 and other default parameters is better than lightgbm with \n",
    "#     default parameters\n",
    "# 3. xgboost with parameters n_estimators=250, learning_rate=0.10, colsample_bytree=0.70, \n",
    "#     max_depth=3 is better than lightgbm with default parameters\n",
    "# 4. xgboost with n_estimators=250, learning_rate=0.10, colsample_bytree=0.70, max_depth=3 \n",
    "#     is better than catboost with iterations=80 and other default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe81dbd",
   "metadata": {},
   "source": [
    "#### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abe953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Using the data for catboost from the previous question, compare a model trained \n",
    "# with default parameters and iterations=80 on all data and models trained on a particular \n",
    "# year's data.\n",
    "\n",
    "# Do I need to build a separate catboost model for each year? Mark the correct answer.*\n",
    "# Yes, because for a particular year, always more accurate predictions\n",
    "# No, because a model built on all the data always beats a model built only on a part\n",
    "# No, because the model for a specific year always predicts a specific year worse than \n",
    "#   the general model\n",
    "# Depends, because some years are special and you need to take this into account when \n",
    "#   choosing a model. In our data, there are about 1 out of 5 such years."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
